import gradio as gr
from faster_whisper import WhisperModel
from TTS.api import TTS
import requests
import os
import json

# -----------------------------
# æ¨¡å‹é…ç½®
# -----------------------------
STT_MODEL = "large-v3"
TTS_MODEL = "tts_models/en/vctk/vits"
LLM_API = "http://localhost:11434/api/chat"
DEFAULT_SPEAKER = "p225"
SPEAKERS = ["p225", "p226", "p248", "p249"]

# -----------------------------
# åˆå§‹åŒ–
# -----------------------------
print("åŠ è½½ Whisper æ¨¡å‹...")
whisper = WhisperModel(STT_MODEL, device="cuda")

print("åŠ è½½ TTS æ¨¡å‹...")
tts = TTS(TTS_MODEL)
tts.to("cuda")

# -----------------------------
# ä¸»é€»è¾‘
# -----------------------------
def process_audio(audio, speaker, dual_output, speed):
    if audio is None:
        return "è¯·å…ˆå½•éŸ³ã€‚", None, None

    os.makedirs("audio", exist_ok=True)
    input_path = "audio/input.wav"
    en_path = "audio/reply_en.wav"
    cn_path = "audio/reply_cn.wav"

    # ä¿å­˜å½•éŸ³
    if isinstance(audio, str):
        input_path = audio
    else:
        audio[1].export(input_path, format="wav")

    # Whisper è¯­éŸ³è½¬æ–‡å­—
    segments, _ = whisper.transcribe(input_path)
    text_in = " ".join([s.text for s in segments])

    # æ„å»º Prompt
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªåŒè¯­åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­è‹±æ–‡å›ç­”é—®é¢˜ã€‚
è¯·ä¸¥æ ¼ä»¥ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚

é—®é¢˜ï¼š{text_in}

è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "chinese": "ä¸­æ–‡å›ç­”å†…å®¹",
  "english": "è‹±æ–‡ç¿»è¯‘å†…å®¹"
}}
"""

    # è°ƒç”¨æœ¬åœ° Mistral LLM
    payload = {"model": "mistral", "messages": [{"role": "user", "content": prompt}]}

    cn_text = ""
    en_text = ""
    try:
        response = requests.post(LLM_API, json=payload)
        response.raise_for_status()
        # å¦‚æœè¿”å›æ˜¯é€è¡Œæµ
        try:
            reply_lines = response.json()
        except Exception:
            reply_lines = response.text.splitlines()

        # æ‹¼æ¥ content
        all_content = ""
        for line in reply_lines:
            try:
                line_json = json.loads(line)
                if "message" in line_json and "content" in line_json["message"]:
                    all_content += line_json["message"]["content"]
            except Exception:
                continue

        # è§£ææœ€ç»ˆ JSON
        try:
            reply_json = json.loads(all_content)
            cn_text = reply_json.get("chinese", "").strip()
            en_text = reply_json.get("english", "").strip()
        except Exception:
            # å¦‚æœæ— æ³•è§£æ JSONï¼Œç›´æ¥æŠŠæ‹¼æ¥åçš„å†…å®¹å½“è‹±æ–‡
            en_text = all_content.strip()

    except Exception as e:
        print(f"âŒ LLM è°ƒç”¨é”™è¯¯: {e}")
        en_text = "LLM è¿”å›å¼‚å¸¸ã€‚"

    # ç”Ÿæˆè‹±æ–‡è¯­éŸ³
    if en_text:
        tts.tts_to_file(text=en_text, speaker=speaker, file_path=en_path, speed=speed)

    # ç”Ÿæˆä¸­æ–‡è¯­éŸ³ï¼ˆå¦‚æœé€‰æ‹©äº† dual_outputï¼‰
    if dual_output and cn_text:
        tts.tts_to_file(text=cn_text, speaker=speaker, file_path=cn_path, speed=speed)
        return f"ğŸ—£ï¸ ä½ è¯´: {text_in}\n\nğŸ¤– ä¸­æ–‡: {cn_text}\n\nğŸ’¬ English: {en_text}", en_path, cn_path
    else:
        return f"ğŸ—£ï¸ ä½ è¯´: {text_in}\n\nğŸ’¬ English: {en_text}", en_path, None

# -----------------------------
# Gradio UI
# -----------------------------
def build_ui():
    with gr.Blocks() as demo:
        gr.Markdown("## ğŸ§ æœ¬åœ°è¯­éŸ³å¯¹è¯ AI åŠ©æ‰‹ï¼ˆä¸­è‹±åŒè¯­ç‰ˆï¼‰")

        with gr.Row():
            audio_input = gr.Audio(sources=["microphone"], type="filepath", label="ğŸ™ï¸ å½•éŸ³è¾“å…¥")
            speaker_choice = gr.Dropdown(SPEAKERS, value=DEFAULT_SPEAKER, label="ğŸ”Š å£°éŸ³é€‰æ‹©")
            dual_output = gr.Checkbox(label="ğŸµ åŒæ—¶è¾“å‡ºä¸­æ–‡å’Œè‹±æ–‡", value=False)
            speed_slider = gr.Slider(minimum=0.6, maximum=1.2, step=0.05, value=1.0, label="â© è¯­é€Ÿ")

        output_text = gr.Textbox(label="ğŸ’¬ å¯¹è¯æ–‡å­—", lines=5, interactive=False)
        with gr.Row():
            audio_output_en = gr.Audio(label="ğŸ”Š è‹±æ–‡è¯­éŸ³")
            audio_output_cn = gr.Audio(label="ğŸ”Š ä¸­æ–‡è¯­éŸ³ï¼ˆå¯é€‰ï¼‰")

        btn = gr.Button("å¼€å§‹å¯¹è¯")

        btn.click(
            process_audio,
            inputs=[audio_input, speaker_choice, dual_output, speed_slider],
            outputs=[output_text, audio_output_en, audio_output_cn],
        )

    return demo

# -----------------------------
# å¯åŠ¨
# -----------------------------
if __name__ == "__main__":
    ui = build_ui()
    ui.launch()
